{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lim.the/fast-influence-functions\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params Trainable: 14768643\n",
      "\tbert.encoder.layer.10.attention.self.query.weight\n",
      "\tbert.encoder.layer.10.attention.self.query.bias\n",
      "\tbert.encoder.layer.10.attention.self.key.weight\n",
      "\tbert.encoder.layer.10.attention.self.key.bias\n",
      "\tbert.encoder.layer.10.attention.self.value.weight\n",
      "\tbert.encoder.layer.10.attention.self.value.bias\n",
      "\tbert.encoder.layer.10.attention.output.dense.weight\n",
      "\tbert.encoder.layer.10.attention.output.dense.bias\n",
      "\tbert.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "\tbert.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "\tbert.encoder.layer.10.intermediate.dense.weight\n",
      "\tbert.encoder.layer.10.intermediate.dense.bias\n",
      "\tbert.encoder.layer.10.output.dense.weight\n",
      "\tbert.encoder.layer.10.output.dense.bias\n",
      "\tbert.encoder.layer.10.output.LayerNorm.weight\n",
      "\tbert.encoder.layer.10.output.LayerNorm.bias\n",
      "\tbert.encoder.layer.11.attention.self.query.weight\n",
      "\tbert.encoder.layer.11.attention.self.query.bias\n",
      "\tbert.encoder.layer.11.attention.self.key.weight\n",
      "\tbert.encoder.layer.11.attention.self.key.bias\n",
      "\tbert.encoder.layer.11.attention.self.value.weight\n",
      "\tbert.encoder.layer.11.attention.self.value.bias\n",
      "\tbert.encoder.layer.11.attention.output.dense.weight\n",
      "\tbert.encoder.layer.11.attention.output.dense.bias\n",
      "\tbert.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "\tbert.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "\tbert.encoder.layer.11.intermediate.dense.weight\n",
      "\tbert.encoder.layer.11.intermediate.dense.bias\n",
      "\tbert.encoder.layer.11.output.dense.weight\n",
      "\tbert.encoder.layer.11.output.dense.bias\n",
      "\tbert.encoder.layer.11.output.LayerNorm.weight\n",
      "\tbert.encoder.layer.11.output.LayerNorm.bias\n",
      "\tbert.pooler.dense.weight\n",
      "\tbert.pooler.dense.bias\n",
      "\tclassifier.weight\n",
      "\tclassifier.bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3068/3068 [28:17<00:00,  1.81it/s]\n"
     ]
    }
   ],
   "source": [
    "import self_code\n",
    "MNLI = self_code.create_FAISS_index_sim_metrics(train_task_name=\"mnli\", \n",
    "                                                trained_on_task_name =\"mnli\",\n",
    "                                                similarity=\"pred_feature\",\n",
    "                                                metric = \"cosine_similarity\")\n",
    "MNLI.save(\"faiss_index_pred_feat/MNLI.index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params Trainable: 14767874\n",
      "\tbert.encoder.layer.10.attention.self.query.weight\n",
      "\tbert.encoder.layer.10.attention.self.query.bias\n",
      "\tbert.encoder.layer.10.attention.self.key.weight\n",
      "\tbert.encoder.layer.10.attention.self.key.bias\n",
      "\tbert.encoder.layer.10.attention.self.value.weight\n",
      "\tbert.encoder.layer.10.attention.self.value.bias\n",
      "\tbert.encoder.layer.10.attention.output.dense.weight\n",
      "\tbert.encoder.layer.10.attention.output.dense.bias\n",
      "\tbert.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "\tbert.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "\tbert.encoder.layer.10.intermediate.dense.weight\n",
      "\tbert.encoder.layer.10.intermediate.dense.bias\n",
      "\tbert.encoder.layer.10.output.dense.weight\n",
      "\tbert.encoder.layer.10.output.dense.bias\n",
      "\tbert.encoder.layer.10.output.LayerNorm.weight\n",
      "\tbert.encoder.layer.10.output.LayerNorm.bias\n",
      "\tbert.encoder.layer.11.attention.self.query.weight\n",
      "\tbert.encoder.layer.11.attention.self.query.bias\n",
      "\tbert.encoder.layer.11.attention.self.key.weight\n",
      "\tbert.encoder.layer.11.attention.self.key.bias\n",
      "\tbert.encoder.layer.11.attention.self.value.weight\n",
      "\tbert.encoder.layer.11.attention.self.value.bias\n",
      "\tbert.encoder.layer.11.attention.output.dense.weight\n",
      "\tbert.encoder.layer.11.attention.output.dense.bias\n",
      "\tbert.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "\tbert.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "\tbert.encoder.layer.11.intermediate.dense.weight\n",
      "\tbert.encoder.layer.11.intermediate.dense.bias\n",
      "\tbert.encoder.layer.11.output.dense.weight\n",
      "\tbert.encoder.layer.11.output.dense.bias\n",
      "\tbert.encoder.layer.11.output.LayerNorm.weight\n",
      "\tbert.encoder.layer.11.output.LayerNorm.bias\n",
      "\tbert.pooler.dense.weight\n",
      "\tbert.pooler.dense.bias\n",
      "\tclassifier.weight\n",
      "\tclassifier.bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3068/3068 [28:53<00:00,  1.77it/s]\n"
     ]
    }
   ],
   "source": [
    "import self_code\n",
    "MNLI2 = self_code.create_FAISS_index_sim_metrics(train_task_name=\"mnli-2\", \n",
    "                                                trained_on_task_name =\"mnli-2\",\n",
    "                                                similarity=\"pred_feature\",\n",
    "                                                metric = \"inner_product\")\n",
    "MNLI2.save(\"faiss_index_pred_feat/MNLI2.index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params Trainable: 14767874\n",
      "\tbert.encoder.layer.10.attention.self.query.weight\n",
      "\tbert.encoder.layer.10.attention.self.query.bias\n",
      "\tbert.encoder.layer.10.attention.self.key.weight\n",
      "\tbert.encoder.layer.10.attention.self.key.bias\n",
      "\tbert.encoder.layer.10.attention.self.value.weight\n",
      "\tbert.encoder.layer.10.attention.self.value.bias\n",
      "\tbert.encoder.layer.10.attention.output.dense.weight\n",
      "\tbert.encoder.layer.10.attention.output.dense.bias\n",
      "\tbert.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "\tbert.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "\tbert.encoder.layer.10.intermediate.dense.weight\n",
      "\tbert.encoder.layer.10.intermediate.dense.bias\n",
      "\tbert.encoder.layer.10.output.dense.weight\n",
      "\tbert.encoder.layer.10.output.dense.bias\n",
      "\tbert.encoder.layer.10.output.LayerNorm.weight\n",
      "\tbert.encoder.layer.10.output.LayerNorm.bias\n",
      "\tbert.encoder.layer.11.attention.self.query.weight\n",
      "\tbert.encoder.layer.11.attention.self.query.bias\n",
      "\tbert.encoder.layer.11.attention.self.key.weight\n",
      "\tbert.encoder.layer.11.attention.self.key.bias\n",
      "\tbert.encoder.layer.11.attention.self.value.weight\n",
      "\tbert.encoder.layer.11.attention.self.value.bias\n",
      "\tbert.encoder.layer.11.attention.output.dense.weight\n",
      "\tbert.encoder.layer.11.attention.output.dense.bias\n",
      "\tbert.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "\tbert.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "\tbert.encoder.layer.11.intermediate.dense.weight\n",
      "\tbert.encoder.layer.11.intermediate.dense.bias\n",
      "\tbert.encoder.layer.11.output.dense.weight\n",
      "\tbert.encoder.layer.11.output.dense.bias\n",
      "\tbert.encoder.layer.11.output.LayerNorm.weight\n",
      "\tbert.encoder.layer.11.output.LayerNorm.bias\n",
      "\tbert.pooler.dense.weight\n",
      "\tbert.pooler.dense.bias\n",
      "\tclassifier.weight\n",
      "\tclassifier.bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [02:12<00:00,  1.78it/s]\n"
     ]
    }
   ],
   "source": [
    "import self_code\n",
    "MNLI2_HANS = self_code.create_FAISS_index_sim_metrics(train_task_name=\"hans\", \n",
    "                                                trained_on_task_name =\"mnli-2\",\n",
    "                                                similarity=\"pred_feature\",\n",
    "                                                metric = \"inner_product\")\n",
    "MNLI2_HANS.save(\"faiss_index_pred_feat/MNLI2_HANS.index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params Trainable: 14768643\n",
      "\tbert.encoder.layer.10.attention.self.query.weight\n",
      "\tbert.encoder.layer.10.attention.self.query.bias\n",
      "\tbert.encoder.layer.10.attention.self.key.weight\n",
      "\tbert.encoder.layer.10.attention.self.key.bias\n",
      "\tbert.encoder.layer.10.attention.self.value.weight\n",
      "\tbert.encoder.layer.10.attention.self.value.bias\n",
      "\tbert.encoder.layer.10.attention.output.dense.weight\n",
      "\tbert.encoder.layer.10.attention.output.dense.bias\n",
      "\tbert.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "\tbert.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "\tbert.encoder.layer.10.intermediate.dense.weight\n",
      "\tbert.encoder.layer.10.intermediate.dense.bias\n",
      "\tbert.encoder.layer.10.output.dense.weight\n",
      "\tbert.encoder.layer.10.output.dense.bias\n",
      "\tbert.encoder.layer.10.output.LayerNorm.weight\n",
      "\tbert.encoder.layer.10.output.LayerNorm.bias\n",
      "\tbert.encoder.layer.11.attention.self.query.weight\n",
      "\tbert.encoder.layer.11.attention.self.query.bias\n",
      "\tbert.encoder.layer.11.attention.self.key.weight\n",
      "\tbert.encoder.layer.11.attention.self.key.bias\n",
      "\tbert.encoder.layer.11.attention.self.value.weight\n",
      "\tbert.encoder.layer.11.attention.self.value.bias\n",
      "\tbert.encoder.layer.11.attention.output.dense.weight\n",
      "\tbert.encoder.layer.11.attention.output.dense.bias\n",
      "\tbert.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "\tbert.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "\tbert.encoder.layer.11.intermediate.dense.weight\n",
      "\tbert.encoder.layer.11.intermediate.dense.bias\n",
      "\tbert.encoder.layer.11.output.dense.weight\n",
      "\tbert.encoder.layer.11.output.dense.bias\n",
      "\tbert.encoder.layer.11.output.LayerNorm.weight\n",
      "\tbert.encoder.layer.11.output.LayerNorm.bias\n",
      "\tbert.pooler.dense.weight\n",
      "\tbert.pooler.dense.bias\n",
      "\tclassifier.weight\n",
      "\tclassifier.bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/392702 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from experiments import hans\n",
    "preds, label_one_hot, pred_label_diff  = hans.create_FAISS_index_pred_feat(\"mnli\", \"mnli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02176733, 0.71152425, 0.26670846]], dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02176733,  0.71152425, -0.73329154]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_label_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params Trainable: 14767874\n",
      "\tbert.encoder.layer.10.attention.self.query.weight\n",
      "\tbert.encoder.layer.10.attention.self.query.bias\n",
      "\tbert.encoder.layer.10.attention.self.key.weight\n",
      "\tbert.encoder.layer.10.attention.self.key.bias\n",
      "\tbert.encoder.layer.10.attention.self.value.weight\n",
      "\tbert.encoder.layer.10.attention.self.value.bias\n",
      "\tbert.encoder.layer.10.attention.output.dense.weight\n",
      "\tbert.encoder.layer.10.attention.output.dense.bias\n",
      "\tbert.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "\tbert.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "\tbert.encoder.layer.10.intermediate.dense.weight\n",
      "\tbert.encoder.layer.10.intermediate.dense.bias\n",
      "\tbert.encoder.layer.10.output.dense.weight\n",
      "\tbert.encoder.layer.10.output.dense.bias\n",
      "\tbert.encoder.layer.10.output.LayerNorm.weight\n",
      "\tbert.encoder.layer.10.output.LayerNorm.bias\n",
      "\tbert.encoder.layer.11.attention.self.query.weight\n",
      "\tbert.encoder.layer.11.attention.self.query.bias\n",
      "\tbert.encoder.layer.11.attention.self.key.weight\n",
      "\tbert.encoder.layer.11.attention.self.key.bias\n",
      "\tbert.encoder.layer.11.attention.self.value.weight\n",
      "\tbert.encoder.layer.11.attention.self.value.bias\n",
      "\tbert.encoder.layer.11.attention.output.dense.weight\n",
      "\tbert.encoder.layer.11.attention.output.dense.bias\n",
      "\tbert.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "\tbert.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "\tbert.encoder.layer.11.intermediate.dense.weight\n",
      "\tbert.encoder.layer.11.intermediate.dense.bias\n",
      "\tbert.encoder.layer.11.output.dense.weight\n",
      "\tbert.encoder.layer.11.output.dense.bias\n",
      "\tbert.encoder.layer.11.output.LayerNorm.weight\n",
      "\tbert.encoder.layer.11.output.LayerNorm.bias\n",
      "\tbert.pooler.dense.weight\n",
      "\tbert.pooler.dense.bias\n",
      "\tclassifier.weight\n",
      "\tclassifier.bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3068/3068 [13:37<00:00,  3.75it/s]\n"
     ]
    }
   ],
   "source": [
    "HANS_MNLI2 = hans.create_FAISS_index(train_task_name=\"mnli-2\", trained_on_task_name =\"hans\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "HANS_MNLI2.save(\"faiss_index/HANS_MNLI2.index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params Trainable: 14767874\n",
      "\tbert.encoder.layer.10.attention.self.query.weight\n",
      "\tbert.encoder.layer.10.attention.self.query.bias\n",
      "\tbert.encoder.layer.10.attention.self.key.weight\n",
      "\tbert.encoder.layer.10.attention.self.key.bias\n",
      "\tbert.encoder.layer.10.attention.self.value.weight\n",
      "\tbert.encoder.layer.10.attention.self.value.bias\n",
      "\tbert.encoder.layer.10.attention.output.dense.weight\n",
      "\tbert.encoder.layer.10.attention.output.dense.bias\n",
      "\tbert.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "\tbert.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "\tbert.encoder.layer.10.intermediate.dense.weight\n",
      "\tbert.encoder.layer.10.intermediate.dense.bias\n",
      "\tbert.encoder.layer.10.output.dense.weight\n",
      "\tbert.encoder.layer.10.output.dense.bias\n",
      "\tbert.encoder.layer.10.output.LayerNorm.weight\n",
      "\tbert.encoder.layer.10.output.LayerNorm.bias\n",
      "\tbert.encoder.layer.11.attention.self.query.weight\n",
      "\tbert.encoder.layer.11.attention.self.query.bias\n",
      "\tbert.encoder.layer.11.attention.self.key.weight\n",
      "\tbert.encoder.layer.11.attention.self.key.bias\n",
      "\tbert.encoder.layer.11.attention.self.value.weight\n",
      "\tbert.encoder.layer.11.attention.self.value.bias\n",
      "\tbert.encoder.layer.11.attention.output.dense.weight\n",
      "\tbert.encoder.layer.11.attention.output.dense.bias\n",
      "\tbert.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "\tbert.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "\tbert.encoder.layer.11.intermediate.dense.weight\n",
      "\tbert.encoder.layer.11.intermediate.dense.bias\n",
      "\tbert.encoder.layer.11.output.dense.weight\n",
      "\tbert.encoder.layer.11.output.dense.bias\n",
      "\tbert.encoder.layer.11.output.LayerNorm.weight\n",
      "\tbert.encoder.layer.11.output.LayerNorm.bias\n",
      "\tbert.pooler.dense.weight\n",
      "\tbert.pooler.dense.bias\n",
      "\tclassifier.weight\n",
      "\tclassifier.bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [01:01<00:00,  3.81it/s]\n"
     ]
    }
   ],
   "source": [
    "MNLI2_HANS = hans.create_FAISS_index(train_task_name=\"hans\", trained_on_task_name =\"mnli-2\")\n",
    "MNLI2_HANS.save(\"faiss_index/MNLI2_HANS.index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params Trainable: 14767874\n",
      "\tbert.encoder.layer.10.attention.self.query.weight\n",
      "\tbert.encoder.layer.10.attention.self.query.bias\n",
      "\tbert.encoder.layer.10.attention.self.key.weight\n",
      "\tbert.encoder.layer.10.attention.self.key.bias\n",
      "\tbert.encoder.layer.10.attention.self.value.weight\n",
      "\tbert.encoder.layer.10.attention.self.value.bias\n",
      "\tbert.encoder.layer.10.attention.output.dense.weight\n",
      "\tbert.encoder.layer.10.attention.output.dense.bias\n",
      "\tbert.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "\tbert.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "\tbert.encoder.layer.10.intermediate.dense.weight\n",
      "\tbert.encoder.layer.10.intermediate.dense.bias\n",
      "\tbert.encoder.layer.10.output.dense.weight\n",
      "\tbert.encoder.layer.10.output.dense.bias\n",
      "\tbert.encoder.layer.10.output.LayerNorm.weight\n",
      "\tbert.encoder.layer.10.output.LayerNorm.bias\n",
      "\tbert.encoder.layer.11.attention.self.query.weight\n",
      "\tbert.encoder.layer.11.attention.self.query.bias\n",
      "\tbert.encoder.layer.11.attention.self.key.weight\n",
      "\tbert.encoder.layer.11.attention.self.key.bias\n",
      "\tbert.encoder.layer.11.attention.self.value.weight\n",
      "\tbert.encoder.layer.11.attention.self.value.bias\n",
      "\tbert.encoder.layer.11.attention.output.dense.weight\n",
      "\tbert.encoder.layer.11.attention.output.dense.bias\n",
      "\tbert.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "\tbert.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "\tbert.encoder.layer.11.intermediate.dense.weight\n",
      "\tbert.encoder.layer.11.intermediate.dense.bias\n",
      "\tbert.encoder.layer.11.output.dense.weight\n",
      "\tbert.encoder.layer.11.output.dense.bias\n",
      "\tbert.encoder.layer.11.output.LayerNorm.weight\n",
      "\tbert.encoder.layer.11.output.LayerNorm.bias\n",
      "\tbert.pooler.dense.weight\n",
      "\tbert.pooler.dense.bias\n",
      "\tclassifier.weight\n",
      "\tclassifier.bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3068/3068 [13:37<00:00,  3.75it/s]\n"
     ]
    }
   ],
   "source": [
    "MNLI2 = hans.create_FAISS_index(train_task_name=\"mnli-2\", trained_on_task_name =\"mnli-2\")\n",
    "MNLI2.save(\"faiss_index/MNLI2.index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params Trainable: 14767874\n",
      "\tbert.encoder.layer.10.attention.self.query.weight\n",
      "\tbert.encoder.layer.10.attention.self.query.bias\n",
      "\tbert.encoder.layer.10.attention.self.key.weight\n",
      "\tbert.encoder.layer.10.attention.self.key.bias\n",
      "\tbert.encoder.layer.10.attention.self.value.weight\n",
      "\tbert.encoder.layer.10.attention.self.value.bias\n",
      "\tbert.encoder.layer.10.attention.output.dense.weight\n",
      "\tbert.encoder.layer.10.attention.output.dense.bias\n",
      "\tbert.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "\tbert.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "\tbert.encoder.layer.10.intermediate.dense.weight\n",
      "\tbert.encoder.layer.10.intermediate.dense.bias\n",
      "\tbert.encoder.layer.10.output.dense.weight\n",
      "\tbert.encoder.layer.10.output.dense.bias\n",
      "\tbert.encoder.layer.10.output.LayerNorm.weight\n",
      "\tbert.encoder.layer.10.output.LayerNorm.bias\n",
      "\tbert.encoder.layer.11.attention.self.query.weight\n",
      "\tbert.encoder.layer.11.attention.self.query.bias\n",
      "\tbert.encoder.layer.11.attention.self.key.weight\n",
      "\tbert.encoder.layer.11.attention.self.key.bias\n",
      "\tbert.encoder.layer.11.attention.self.value.weight\n",
      "\tbert.encoder.layer.11.attention.self.value.bias\n",
      "\tbert.encoder.layer.11.attention.output.dense.weight\n",
      "\tbert.encoder.layer.11.attention.output.dense.bias\n",
      "\tbert.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "\tbert.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "\tbert.encoder.layer.11.intermediate.dense.weight\n",
      "\tbert.encoder.layer.11.intermediate.dense.bias\n",
      "\tbert.encoder.layer.11.output.dense.weight\n",
      "\tbert.encoder.layer.11.output.dense.bias\n",
      "\tbert.encoder.layer.11.output.LayerNorm.weight\n",
      "\tbert.encoder.layer.11.output.LayerNorm.bias\n",
      "\tbert.pooler.dense.weight\n",
      "\tbert.pooler.dense.bias\n",
      "\tclassifier.weight\n",
      "\tclassifier.bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [01:02<00:00,  3.78it/s]\n"
     ]
    }
   ],
   "source": [
    "HANS = hans.create_FAISS_index(train_task_name=\"hans\", trained_on_task_name =\"hans\")\n",
    "HANS.save(\"faiss_index/HANS.index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thean added the function below to get FAISS indices\n",
    "# for MNLI-MNLI combination.\n",
    "\n",
    "\n",
    "from experiments import constants, misc_utils\n",
    "from influence_utils import faiss_utils\n",
    "from tqdm import tqdm\n",
    "\n",
    "def create_FAISS_index_mnli() -> faiss_utils.FAISSIndex:\n",
    "    tokenizer, model = misc_utils.create_tokenizer_and_model(constants.MNLI_MODEL_PATH)\n",
    "    \n",
    "    train_dataset, _ = misc_utils.create_datasets(\n",
    "        task_name=\"mnli\",\n",
    "        tokenizer=tokenizer)\n",
    "\n",
    "    faiss_index = faiss_utils.FAISSIndex(768, \"Flat\")\n",
    "\n",
    "    model.cuda()\n",
    "    device = model.device\n",
    "    train_batch_data_loader = misc_utils.get_dataloader(\n",
    "        dataset=train_dataset,\n",
    "        batch_size=1,\n",
    "        random=False)\n",
    "\n",
    "    for inputs in tqdm(train_batch_data_loader):\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        features = misc_utils.compute_BERT_CLS_feature(model, **inputs)\n",
    "        features = features.cpu().detach().numpy()\n",
    "        return features\n",
    "        faiss_index.add(features)\n",
    "\n",
    "    return faiss_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params Trainable: 14768643\n",
      "\tbert.encoder.layer.10.attention.self.query.weight\n",
      "\tbert.encoder.layer.10.attention.self.query.bias\n",
      "\tbert.encoder.layer.10.attention.self.key.weight\n",
      "\tbert.encoder.layer.10.attention.self.key.bias\n",
      "\tbert.encoder.layer.10.attention.self.value.weight\n",
      "\tbert.encoder.layer.10.attention.self.value.bias\n",
      "\tbert.encoder.layer.10.attention.output.dense.weight\n",
      "\tbert.encoder.layer.10.attention.output.dense.bias\n",
      "\tbert.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "\tbert.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "\tbert.encoder.layer.10.intermediate.dense.weight\n",
      "\tbert.encoder.layer.10.intermediate.dense.bias\n",
      "\tbert.encoder.layer.10.output.dense.weight\n",
      "\tbert.encoder.layer.10.output.dense.bias\n",
      "\tbert.encoder.layer.10.output.LayerNorm.weight\n",
      "\tbert.encoder.layer.10.output.LayerNorm.bias\n",
      "\tbert.encoder.layer.11.attention.self.query.weight\n",
      "\tbert.encoder.layer.11.attention.self.query.bias\n",
      "\tbert.encoder.layer.11.attention.self.key.weight\n",
      "\tbert.encoder.layer.11.attention.self.key.bias\n",
      "\tbert.encoder.layer.11.attention.self.value.weight\n",
      "\tbert.encoder.layer.11.attention.self.value.bias\n",
      "\tbert.encoder.layer.11.attention.output.dense.weight\n",
      "\tbert.encoder.layer.11.attention.output.dense.bias\n",
      "\tbert.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "\tbert.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "\tbert.encoder.layer.11.intermediate.dense.weight\n",
      "\tbert.encoder.layer.11.intermediate.dense.bias\n",
      "\tbert.encoder.layer.11.output.dense.weight\n",
      "\tbert.encoder.layer.11.output.dense.bias\n",
      "\tbert.encoder.layer.11.output.LayerNorm.weight\n",
      "\tbert.encoder.layer.11.output.LayerNorm.bias\n",
      "\tbert.pooler.dense.weight\n",
      "\tbert.pooler.dense.bias\n",
      "\tclassifier.weight\n",
      "\tclassifier.bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/392702 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "MNLI = create_FAISS_index_mnli()\n",
    "#MNLI.save(\"faiss_index/MNLI.index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.87900081e-01, -6.16983362e-02,  9.78176236e-01,\n",
       "        -5.56384921e-01, -4.07358631e-02, -4.31063026e-01,\n",
       "         4.28389847e-01, -3.09877992e-01, -4.33538586e-01,\n",
       "         3.21946107e-02,  5.10617793e-01,  8.11506391e-01,\n",
       "        -7.71521091e-01, -9.34308887e-01, -2.54590452e-01,\n",
       "        -2.46331275e-01,  4.87389743e-01, -7.16922879e-02,\n",
       "        -9.90684271e-01,  1.04527047e-03, -1.03859395e-01,\n",
       "        -9.72058177e-01,  4.27847296e-01, -3.61334495e-02,\n",
       "        -3.71608317e-01,  1.25622153e-01,  5.60697317e-01,\n",
       "         9.90444243e-01, -3.98207694e-01,  2.28241086e-01,\n",
       "         2.93981016e-01, -6.36737108e-01, -7.80581236e-01,\n",
       "        -8.86787117e-01,  3.44575971e-01, -1.02216952e-01,\n",
       "        -2.80790657e-01,  1.68946207e-01, -4.10982817e-01,\n",
       "         2.35291317e-01,  2.09211946e-01, -1.58421755e-01,\n",
       "        -3.70850191e-02, -2.34245569e-01,  5.83637320e-02,\n",
       "         4.45713937e-01,  3.57930511e-01,  1.52540877e-01,\n",
       "         2.48632357e-01,  9.70309973e-01,  2.50744298e-02,\n",
       "         9.48413730e-01, -3.94381464e-01,  7.30061710e-01,\n",
       "         6.35082841e-01,  1.32563889e-01,  7.29383230e-01,\n",
       "        -1.52045339e-01, -9.60292220e-02,  1.76053435e-01,\n",
       "         1.97734699e-01, -4.43370730e-01,  4.04891185e-02,\n",
       "         1.31406084e-01,  1.56565189e-01, -4.28052902e-01,\n",
       "         5.26323676e-01,  4.33492631e-01,  2.43270114e-01,\n",
       "         1.06921345e-01, -4.00474042e-01,  8.69016498e-02,\n",
       "         8.00793171e-01, -1.46394029e-01,  4.15545523e-01,\n",
       "        -1.42723367e-01, -3.97457071e-02, -9.33047712e-01,\n",
       "         1.88083947e-01,  9.14765000e-01,  3.66790384e-01,\n",
       "        -9.48211432e-01,  6.51391149e-01, -3.51670086e-01,\n",
       "         5.22581100e-01, -8.73254597e-01, -2.06254646e-01,\n",
       "        -9.52177107e-01,  1.44605324e-01,  3.82555723e-01,\n",
       "        -7.02322870e-02, -6.87555611e-01,  1.02629118e-01,\n",
       "         1.76267341e-01,  9.86464620e-01, -6.03465736e-01,\n",
       "         3.62544544e-02,  2.34487861e-01,  2.42918767e-02,\n",
       "        -6.82707489e-01, -3.93164545e-01,  4.56915498e-02,\n",
       "         7.00706363e-01, -4.90432590e-01,  8.43877673e-01,\n",
       "         2.40785152e-01, -2.60819614e-01,  4.82809395e-02,\n",
       "        -6.90919161e-01,  4.85156596e-01,  7.50557005e-01,\n",
       "        -2.77933627e-01, -5.55877924e-01,  4.62801099e-01,\n",
       "        -6.34371877e-01, -9.19382095e-01,  3.93718600e-01,\n",
       "         5.98572850e-01, -4.68987972e-02,  9.55923021e-01,\n",
       "        -1.00839153e-01, -7.90844485e-02,  8.78562033e-01,\n",
       "        -1.04849167e-01, -4.65713918e-01, -3.50119054e-01,\n",
       "         4.86816108e-01, -1.16137089e-02, -2.15189382e-01,\n",
       "        -1.72928318e-01,  1.47441283e-01, -6.85266137e-01,\n",
       "        -4.76941943e-01,  8.22595119e-01, -4.26234931e-01,\n",
       "         9.56877649e-01, -9.14987087e-01,  2.61810005e-01,\n",
       "        -9.74902749e-01, -8.26666117e-01,  6.98720217e-01,\n",
       "        -5.20384014e-02,  9.81483259e-04,  4.02999908e-01,\n",
       "         6.08892262e-01,  4.85476553e-01, -8.09096023e-02,\n",
       "        -3.92947376e-01,  2.09631608e-03,  4.78875905e-01,\n",
       "         7.77022243e-01,  4.91405815e-01,  2.16456391e-02,\n",
       "         9.61747229e-01, -1.98358864e-01, -3.15139592e-01,\n",
       "         1.19278140e-01,  4.82806772e-01,  2.46730685e-01,\n",
       "         4.51837689e-01,  1.81105196e-01, -8.28983545e-01,\n",
       "        -7.00195909e-01, -1.67825297e-01,  2.97304064e-01,\n",
       "         2.69542813e-01, -7.83993840e-01, -7.26798773e-01,\n",
       "         9.03445065e-01,  6.86382949e-01, -4.26299572e-01,\n",
       "        -2.69884855e-01, -6.07892871e-01, -6.90801680e-01,\n",
       "        -1.57340229e-01,  1.81456819e-01, -1.05809560e-02,\n",
       "         8.93747091e-01, -7.07370996e-01,  6.37896836e-01,\n",
       "         9.77141380e-01,  1.45449013e-01, -2.93578953e-01,\n",
       "         6.96887195e-01, -7.18244195e-01, -7.78545976e-01,\n",
       "        -6.26180291e-01,  2.99711764e-01,  9.57942382e-02,\n",
       "        -2.16986001e-01,  3.17929722e-02,  4.58585143e-01,\n",
       "         1.79244220e-01, -1.02893867e-01, -6.10498548e-01,\n",
       "        -2.51256764e-01,  1.48655415e-01, -2.01051496e-02,\n",
       "         9.49266255e-01,  5.49097061e-01, -8.78122032e-01,\n",
       "         5.38206518e-01, -1.25439435e-01,  5.20642400e-01,\n",
       "         2.83441663e-01,  5.32260239e-01,  5.80754243e-02,\n",
       "        -1.53729483e-01,  8.38010192e-01, -9.88537431e-01,\n",
       "         6.77707791e-01,  1.86222926e-01, -2.60356963e-01,\n",
       "         2.00862158e-02,  2.86965698e-01,  2.05888152e-01,\n",
       "        -6.64259195e-01, -1.81313604e-01, -7.47415349e-02,\n",
       "         9.88419950e-01, -9.54330504e-01, -2.70681202e-01,\n",
       "        -3.21938843e-01, -6.74942613e-01, -9.05325055e-01,\n",
       "        -1.81158334e-01, -2.24325523e-01,  4.21899229e-01,\n",
       "        -1.64483994e-01, -7.34930754e-01,  1.72128201e-01,\n",
       "         1.78691655e-01,  7.66867757e-01, -2.16174781e-01,\n",
       "         2.19405577e-01, -9.72687006e-01, -6.73828423e-01,\n",
       "         2.31993139e-01,  1.73374966e-01,  3.58321995e-01,\n",
       "         4.81379092e-01, -1.55118912e-01, -3.67525697e-01,\n",
       "        -1.62414655e-01, -3.71337384e-02,  8.56552243e-01,\n",
       "         4.46836233e-01, -5.76468892e-02,  6.19179666e-01,\n",
       "        -3.13784093e-01, -3.43732864e-01,  3.98363709e-01,\n",
       "         2.56492168e-01,  8.39358926e-01,  3.22152287e-01,\n",
       "         7.72003889e-01,  3.57982278e-01, -2.77771533e-01,\n",
       "         3.61922592e-01, -3.78727466e-01, -3.06686759e-01,\n",
       "        -9.77572918e-01, -1.76577389e-01, -6.88665688e-01,\n",
       "         2.14575827e-01, -1.00352578e-01,  5.63006580e-01,\n",
       "        -2.52244294e-01, -5.18387377e-01,  3.63434732e-01,\n",
       "        -8.34576368e-01, -1.55508980e-01,  2.91147888e-01,\n",
       "         8.89548063e-01, -2.50854522e-01, -6.81587696e-01,\n",
       "         6.00359440e-01,  6.78118110e-01, -9.18852210e-01,\n",
       "        -9.65372562e-01,  1.06650796e-02,  9.77572143e-01,\n",
       "        -4.25177485e-01, -5.76936126e-01,  9.79156196e-01,\n",
       "        -4.00027990e-01,  2.10844010e-01, -2.36608937e-01,\n",
       "        -3.58765453e-01, -6.40499830e-01,  4.34287786e-01,\n",
       "         2.11038917e-01, -2.30097815e-01,  4.78862017e-01,\n",
       "         3.25192437e-02,  8.62124413e-02,  4.89696741e-01,\n",
       "         7.83106029e-01, -2.67145097e-01,  2.10653961e-01,\n",
       "         3.75733256e-01, -4.36647654e-01, -9.82179940e-01,\n",
       "        -2.37289235e-01,  2.32602924e-01, -9.87089157e-01,\n",
       "         9.64999080e-01, -4.19062376e-01,  9.76261199e-01,\n",
       "        -8.02248657e-01, -5.47000647e-01, -3.11950222e-02,\n",
       "         8.18117857e-02,  9.79826227e-02,  6.31696641e-01,\n",
       "         9.37003374e-01,  3.64850491e-01,  1.00114092e-01,\n",
       "        -2.11891949e-01, -1.40662372e-01,  2.00132892e-01,\n",
       "        -3.12317967e-01,  5.27237833e-01,  3.04981947e-01,\n",
       "        -1.61184333e-02, -2.88144182e-02, -4.27446663e-02,\n",
       "        -9.90770087e-02, -3.44498008e-01,  8.08441460e-01,\n",
       "         1.03980802e-01,  2.21987084e-01, -3.31158489e-01,\n",
       "         1.57446429e-01,  5.74373245e-01, -2.00838581e-01,\n",
       "        -1.52353331e-01, -1.52042896e-01, -9.79357958e-01,\n",
       "        -3.85490805e-01,  1.04728736e-01, -8.19329977e-01,\n",
       "        -3.46591771e-01, -9.08787906e-01,  3.63097459e-01,\n",
       "        -5.60136259e-01,  8.45751166e-01, -2.68716455e-01,\n",
       "         5.53069234e-01, -6.74826920e-01,  9.40215349e-01,\n",
       "        -6.83615386e-01, -5.10419272e-02, -1.35574296e-01,\n",
       "         9.53755751e-02,  7.78215528e-01,  7.27052748e-01,\n",
       "         7.52883434e-01,  5.81289411e-01, -3.29906434e-01,\n",
       "        -3.73989016e-01, -3.57391655e-01,  5.06500423e-01,\n",
       "        -4.24889445e-01, -4.66266900e-01, -5.62107980e-01,\n",
       "         8.22236538e-01,  5.52959442e-02,  4.81439620e-01,\n",
       "        -9.20395926e-02, -5.36874354e-01, -3.55390847e-01,\n",
       "         9.14488453e-03, -6.36962280e-02, -6.91463053e-01,\n",
       "        -2.43517950e-01, -3.61501515e-01,  4.11020249e-01,\n",
       "         5.87415695e-01,  1.04744866e-01,  5.29826462e-01,\n",
       "         3.55489165e-01, -6.18080914e-01,  6.48703635e-01,\n",
       "         7.39682555e-01,  8.73494446e-01, -3.97571445e-01,\n",
       "         1.75900906e-01,  2.91081578e-01, -1.21960819e-01,\n",
       "        -2.73274332e-01, -3.15048307e-01,  8.07464063e-01,\n",
       "        -7.63019145e-01, -3.95529598e-01, -9.11988139e-01,\n",
       "        -1.73916578e-01,  2.94181854e-02, -4.04090852e-01,\n",
       "         6.29376531e-01,  2.76968300e-01, -1.77574351e-01,\n",
       "        -3.40371206e-03,  5.51203728e-01,  4.05423522e-01,\n",
       "        -2.46711195e-01, -5.12504756e-01,  1.60844386e-01,\n",
       "         1.06830098e-01, -5.26118219e-01, -1.23649523e-01,\n",
       "         1.68988898e-01,  3.69402170e-01,  5.24962366e-01,\n",
       "         2.04093233e-02,  9.82668996e-01,  4.71427500e-01,\n",
       "        -9.84553218e-01, -9.87462252e-02,  3.81496072e-01,\n",
       "        -6.03675961e-01, -8.41423392e-01, -7.77192473e-01,\n",
       "         3.16597044e-01, -4.84476358e-01, -7.03922868e-01,\n",
       "        -5.49251676e-01, -8.22876513e-01, -9.43112910e-01,\n",
       "         4.67503697e-01, -7.06465125e-01, -1.81003034e-01,\n",
       "        -3.65713716e-01,  9.65681374e-01, -3.04956287e-01,\n",
       "         4.21080977e-01,  1.41143233e-01,  6.36906317e-03,\n",
       "         5.52397549e-01, -3.86295468e-01, -4.02597487e-01,\n",
       "        -8.40135157e-01,  7.72544026e-01,  7.62833238e-01,\n",
       "        -5.22669315e-01,  3.89016569e-01, -6.12928271e-01,\n",
       "        -9.17084888e-02, -5.72366834e-01, -5.80243468e-01,\n",
       "         2.53114730e-01,  5.73315144e-01,  6.02883697e-01,\n",
       "        -8.80188823e-01,  6.62299395e-01,  8.47700909e-02,\n",
       "         3.15480739e-01, -5.47812402e-01, -6.39321208e-01,\n",
       "         7.63297439e-01, -9.24767137e-01,  3.95520031e-01,\n",
       "        -3.12639982e-01, -6.79506063e-01,  1.71273127e-01,\n",
       "         4.05583680e-02, -1.29621789e-01, -3.82036388e-01,\n",
       "         6.07357442e-01, -5.56894362e-01, -8.89543593e-01,\n",
       "         2.67935395e-01,  5.91243505e-01,  8.81285071e-01,\n",
       "         5.82102358e-01, -3.54955196e-01, -4.06811714e-01,\n",
       "         1.22517303e-01,  2.87243128e-01, -9.86012101e-01,\n",
       "        -6.13768660e-02,  6.33873463e-01, -2.04805136e-01,\n",
       "         3.77732366e-01,  3.68139356e-01,  5.00356495e-01,\n",
       "         5.93962334e-02,  1.27600521e-01, -6.75051510e-01,\n",
       "        -4.19041723e-01,  1.75182998e-01,  8.20772648e-01,\n",
       "        -3.07726204e-01,  4.72857863e-01, -1.60021875e-02,\n",
       "        -6.22046113e-01,  5.63037872e-01,  8.73550594e-01,\n",
       "        -7.91384459e-01,  5.45309663e-01,  3.18139404e-01,\n",
       "         7.63052344e-01, -1.14915557e-01,  5.79484820e-01,\n",
       "         4.89604741e-01, -9.02835548e-01, -6.21304274e-01,\n",
       "        -2.82494817e-02, -9.83240843e-01,  9.62416887e-01,\n",
       "        -9.49743748e-01, -7.96443317e-03,  1.28562614e-01,\n",
       "         2.58114249e-01,  8.33516896e-01, -1.76897690e-01,\n",
       "        -9.81703162e-01, -7.87442327e-01,  4.44604099e-01,\n",
       "        -3.67684424e-01,  3.55612069e-01, -8.75822976e-02,\n",
       "        -4.86218035e-01, -3.75979573e-01,  4.32126522e-01,\n",
       "         7.71021545e-01,  9.29114640e-01,  9.01980042e-01,\n",
       "        -4.63132530e-01,  8.77884984e-01, -1.55566841e-01,\n",
       "        -6.67536378e-01, -1.62585061e-02, -9.43440020e-01,\n",
       "         4.18860167e-01,  3.64009380e-01,  4.76173997e-01,\n",
       "         3.07652891e-01, -5.20561635e-01,  9.86757040e-01,\n",
       "        -9.37352240e-01,  9.02901888e-01, -9.91318464e-01,\n",
       "        -6.27402902e-01,  7.61207581e-01, -5.75580597e-01,\n",
       "        -2.64659911e-01, -8.79051387e-01, -6.36794746e-01,\n",
       "        -6.97937906e-01,  2.26384968e-01, -3.40884238e-01,\n",
       "         6.22106552e-01, -9.47743297e-01, -8.25943172e-01,\n",
       "        -8.56543705e-02,  4.56911236e-01,  7.06186816e-02,\n",
       "         6.97279692e-01,  4.05835152e-01,  3.12414467e-01,\n",
       "        -1.91395074e-01, -5.42963855e-02, -4.72037107e-01,\n",
       "         6.01287901e-01,  9.62117910e-01,  2.72745073e-01,\n",
       "         3.20314199e-01, -7.07515121e-01,  5.84018826e-01,\n",
       "         2.91365117e-01, -4.74487580e-02, -5.36232702e-02,\n",
       "        -3.47561598e-01, -1.46541506e-01,  4.02701408e-01,\n",
       "        -7.03181267e-01, -1.58164054e-01, -8.12090278e-01,\n",
       "         6.42011821e-01, -4.97103661e-01,  5.51678181e-01,\n",
       "         4.23183382e-01,  7.32133584e-03, -1.12772271e-01,\n",
       "        -5.77253819e-01,  5.03411004e-03, -8.90039325e-01,\n",
       "         7.19823599e-01,  5.70208430e-02,  6.00918643e-02,\n",
       "        -3.46474469e-01,  5.07086635e-01, -6.02582753e-01,\n",
       "         6.87749982e-01,  7.58548200e-01, -9.87297356e-01,\n",
       "        -1.65551096e-01,  5.41475058e-01,  3.55190575e-01,\n",
       "         2.09227711e-01, -8.48583162e-01, -5.17213523e-01,\n",
       "         6.75940871e-01,  7.08146021e-02,  6.07969165e-01,\n",
       "        -3.36576104e-01, -1.79310963e-01, -2.23946437e-01,\n",
       "        -7.44017720e-01, -5.64726219e-02, -1.45202175e-01,\n",
       "        -1.02141663e-01,  3.55864674e-01, -7.82063663e-01,\n",
       "         3.25036943e-01, -2.86981761e-01, -9.62591246e-02,\n",
       "        -9.69257176e-01, -5.71122885e-01, -8.03344905e-01,\n",
       "         2.54508048e-01,  6.16760731e-01,  6.45237386e-01,\n",
       "         9.77867723e-01,  4.79267873e-02, -4.38957602e-01,\n",
       "        -9.61189643e-02, -9.70594466e-01, -2.21784294e-01,\n",
       "         1.45317495e-01,  7.71667482e-03,  1.40284628e-01,\n",
       "         5.15208721e-01,  4.45616961e-01, -6.68327868e-01,\n",
       "        -9.51270640e-01,  4.72234786e-01,  5.11592269e-01,\n",
       "         4.60607231e-01,  6.01922810e-01,  2.62603223e-01,\n",
       "        -2.26363197e-01, -5.36438525e-01, -4.06565696e-01,\n",
       "         1.13435201e-01,  4.22740161e-01, -4.84667152e-01,\n",
       "         8.06914568e-01, -3.14495325e-01,  9.74911988e-01,\n",
       "        -5.97298145e-01, -4.22056317e-01,  2.13684160e-02,\n",
       "        -2.96625078e-01, -4.99222726e-02,  5.22653818e-01,\n",
       "         2.31741756e-01, -3.64195883e-01,  4.00761902e-01,\n",
       "        -8.55340183e-01,  9.39280927e-01, -5.67877829e-01,\n",
       "        -1.27215058e-01,  7.78477788e-01, -7.90424943e-01,\n",
       "        -8.05426478e-01,  6.52607799e-01, -2.73224890e-01,\n",
       "         2.76047308e-02, -3.31031071e-04,  6.57936990e-01,\n",
       "        -6.02314711e-01, -6.15546107e-01, -8.04833710e-01,\n",
       "        -9.54707205e-01,  2.77764767e-01, -7.13388622e-01,\n",
       "         6.82410896e-02, -2.52284616e-01, -9.82466459e-01,\n",
       "         5.72478890e-01,  1.07161880e-01,  9.45597827e-01,\n",
       "        -9.23744202e-01, -2.33766750e-01, -2.60127038e-01,\n",
       "         6.21900916e-01,  1.05030976e-01, -4.11183804e-01,\n",
       "         1.80429384e-01,  7.60026157e-01,  4.56709206e-01,\n",
       "        -9.14869085e-02, -2.38405317e-01,  7.74902701e-02,\n",
       "        -2.87251193e-02,  3.11787158e-01,  7.96993017e-01,\n",
       "         4.33345605e-03,  6.39548421e-01,  4.33729321e-01,\n",
       "        -8.26546192e-01,  9.82651591e-01,  3.70893776e-01,\n",
       "         8.73583913e-01,  2.21356884e-01, -4.21967149e-01,\n",
       "         4.15745169e-01,  2.47963592e-01, -5.71917684e-04,\n",
       "        -8.70650783e-02, -9.65716541e-01,  2.95085311e-01,\n",
       "        -9.79521811e-01, -4.66984034e-01,  2.57723662e-03,\n",
       "         1.21690601e-01, -8.45098495e-01, -6.82433695e-02,\n",
       "        -2.21438408e-02, -9.30503845e-01,  4.37716544e-01,\n",
       "        -6.04865670e-01, -2.69122273e-01, -1.90162078e-01,\n",
       "         3.63811910e-01, -8.55080411e-02,  8.04643631e-01,\n",
       "        -3.23342383e-01, -4.50405329e-01,  1.55422270e-01,\n",
       "        -3.31745893e-01,  8.97741437e-01, -2.90220249e-02,\n",
       "         2.93252110e-01,  4.28867370e-01, -6.66317344e-01,\n",
       "         4.22512442e-01,  3.93039659e-02, -4.66935366e-01,\n",
       "        -7.62066126e-01,  3.46372664e-01,  5.59167624e-01,\n",
       "         3.97545576e-01, -2.93540627e-01, -7.46609688e-01,\n",
       "         3.29354376e-01, -5.44107676e-01,  7.31888056e-01,\n",
       "         2.47445196e-01, -8.98906887e-01, -9.82960105e-01,\n",
       "         5.93351364e-01,  3.56127381e-01,  7.27228880e-01,\n",
       "         2.99683623e-02,  9.78962839e-01,  4.92199332e-01,\n",
       "         3.33807826e-01,  4.54053253e-01, -3.28843296e-01,\n",
       "        -5.17736733e-01,  2.56773591e-01, -4.08932865e-01,\n",
       "         8.16254616e-01, -6.40071273e-01,  7.19234526e-01]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MNLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
